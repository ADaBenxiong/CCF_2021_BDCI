# CCF 2021 BDCI 千言-问题匹配鲁棒性评测

**赛题描述:**

[千言-问题匹配鲁棒性评测 竞赛 - DataFountain](https://www.datafountain.cn/competitions/516)

[2021 CCF BDCI 千言-问题匹配鲁棒性评测(baidu.com)](https://aistudio.baidu.com/aistudio/competition/detail/116/0/introduction)

**成绩：A榜 28 /410**

操作说明
----
**模型训练说明**，配置好run.sh文件，配置好数据以及预训练模型，使用bash run.sh即可开始进行训练。

- data	存放训练模型的数据，官方获取数据
- init_model	存放预训练模型，尝试使用了（roberta_wwm_large, roberta_zh_large, MacBert_large）三种预训练模型
- run.sh	进行训练模型的脚本
- model.py	存放网络模型代码
- data.py	数据预处理代码
- train_pytorch.py	模型训练的主代码

**bad_case分析**，配置好analysis.sh，使用bash analysis.sh即可开始进行bad_case分析

- analysis.sh	分析错误样例的脚本
- bad_case.py	进行错误分析的代码

**其他分析操作**

- pseudo_label.py	打伪标签生成伪标签数据集
- data_analyze.py	数据分析的代码
- vote.py	模型集成推理预测

数据分析
----
该次使用的是未脱敏的数据，可以通过分析bad_case来进行分析，使用规则的方法配合深度网络来准确推理答案。
数据特点
- 数据量大(train:50.6w, dev 2.8w, test_A:5w, test_B:10w)，训练集验证集标签混乱，噪声多
- 数据集正负分布不均匀（负标签多）
- 测试集与训练集以及验证集不同分布， 测试集长度短小，细粒度区分难度大。

||训练集|验证集|测试集A|测试集B|
|--------|--------|--------|--------|--------|
|正负标签比例|0.475：0.525|0.432：0.568|-|-|
|avg_length|10.017|10.573|8.567|-|
|max_length|153|130|48|-|
|min_length|1|0|3|-|

方案总结
----
我们的baseline模型使用单塔模型，使用将query和answer拼接后传入预训练模型中进行特征提取，通过拼接预训练模型最后几层的输出获取语义信息，之后接softmax进行分类。我们尝试的预训练模型有MacBert_large, roberta_wwm_large。
| 模型 | 线上acc |
|--|--|
| roberta_wwm_large | 80.347 |
|macbert_large|79.725|
|roberta_wwm_large + 错字纠错（拼音检查）|86.387|
|roberta_wwm_large + 错字纠错（拼音检查）+ last2cls|86.369|
|macbert_large + 错字纠错（拼音检查）+ last2cls（2080ti）|87.546|
|macbert_large + 错字纠错（拼音检查）+ last2cls（1080ti）|87.644|
|macbert_large + 错字纠错（拼音检查）+ last2cls + 句法规则化预处理(2080ti)|87.677|
|模型集成投票法(2个)|88.321|
|模型集成投票法 + 句法规则化预处理（2个）|88.655|

### 尝试无效的方法

| 方法 | 
|--|
| 对抗训练 |
| 伪标签 |
| 数据清洗|

- 对抗训练尝试FGM的方法，相当于增加扰动，起到数据增强的效果，该赛题尝试无效。
- 伪标签，使用伪标签进行再训练预测，无效果提升，猜测验证集和训练测试集分布不同，难度不一致，导致使用伪标签的方式无效。
- 该赛题的数据较脏，存在诸多的噪声。错误标签极多。尝试使用了五折交叉验证的方式来进行标签纠正，纠正了3k的数据（纠正率目测较高）后再训练，线上分数下降，较为疑惑。

### 未尝试方法

| 方法|
|----|
|K-折交叉训练|
|R-drop正则化|
|平衡标签|

- 由于训练数据量过大，显卡资源较为吃紧，故未进行K-折交叉训练，并且不确定在使用模型集成的方法，再使用K-折交叉训练是否会有提高。
- 根据官方提供paddlepaddle基线数据显示，R-drop貌似在该任务上无效果。

### 尝试一半的方法

| 方法|
|----|
|句法分析判断|
|回译数据增强|

- 通过使用百度的ddparser库，以及使用network库，进行构建图结构，由于该数据集每例数据较短，较为适合，曾经尝试使用构建图的方法，以及尝试使用句法分析规则化的方法。但是未在训练过程中尝试，只是在推理过程尝试，但是由于会引入大量噪声，进行了几天的思考和实验后，最终放弃，较为遗憾。
- 使用回译数据增强的方法通过进行翻译后回译，可以补全部分缺失的主语和宾语，并且使用该方法可以更改句式结构并且将单词补充完整，但是极为遗憾的是，尝试该方法较晚，由于调用百度翻译api接口收费较高，并且个人手中没有机器翻译的模型，并且再进行训练时间不够充足，只尝试在推理中使用也会引入噪声，最终放弃，猜测使用回译数据增强的方式应该在该问题上训练会有提升，实为遗憾。

### 个人弱点总结

- 使用全量数据进行重新模型预训练或者使用半监督的方式，再使用优质标签进行监督训练效果是否会有所提升。
- 数据增强的方法较多且有效，但是却未曾使用数据增强的方法（对于比赛即为重要的环节）

参考链接：

[CCF BDCI 2019 互联网新闻情感分析 复赛top1解决方案 (github.com)](https://github.com/cxy229/BDCI2019-SENTIMENT-CLASSIFICATION)

[CCF BDCI 2020 房产行业聊天问答匹配赛道 A榜47/2985 (github.com)](https://github.com/chenjiashuo123/CCF_2020_BEIKE)

总结
----
比赛刷榜提分是一种工业界的方法，与学术界研究是完全不同的方向。通过堆砌不同的模块，以达到提升推理效果的目的，并且更加贴近于生活。参加此次比赛是检验这段学习的收获，通过参加比赛，了解了一些模型提升的方法，也学习到了一些新的知识，通过写这个github记录下这一个多月的学习生活，对于初学者的我更深的了解一些有关NLP方面的知识。同时也希望该仓库可以给未来参加比赛的新人一些帮助。如果我的代码对您有用，希望可以给个star以示鼓励，万分感谢。
